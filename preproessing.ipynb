{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ftfy\n!pip install scispacy\n!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_sm-0.5.1.tar.gz","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-10T09:58:32.639062Z","iopub.execute_input":"2023-01-10T09:58:32.639922Z","iopub.status.idle":"2023-01-10T09:59:39.512351Z","shell.execute_reply.started":"2023-01-10T09:58:32.639832Z","shell.execute_reply":"2023-01-10T09:59:39.511080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport nltk\nfrom nltk.corpus import stopwords\nfrom ftfy import fix_encoding\nnltk.download('stopwords')\nnltk.download('punkt')     # download toolkit for textblob.TextBlob.words\nimport re\nfrom tqdm import tqdm\nfrom transformers import AutoTokenizer\nimport spacy\n\nfrom scispacy.abbreviation import AbbreviationDetector\nfrom scispacy.umls_linking import UmlsEntityLinker\nfrom textblob import TextBlob\nimport regex\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer     # tranform expanding words of words like attacker, attacked, attacking -> attack\nstop_words = stopwords.words('english')","metadata":{"execution":{"iopub.status.busy":"2023-01-10T09:59:39.515352Z","iopub.execute_input":"2023-01-10T09:59:39.515860Z","iopub.status.idle":"2023-01-10T09:59:50.659041Z","shell.execute_reply.started":"2023-01-10T09:59:39.515809Z","shell.execute_reply":"2023-01-10T09:59:50.657933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"work_path = \"./\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(text):\n    tokens = []\n    text = str(text)\n    text = text.strip()\n    text = text.lower()\n    regex = re.compile(r'<.*?>')\n    text = re.sub(regex, '', text)\n    text = re.sub(r\"http\\S+\", \"\", text)\n    regex = re.compile(r'&#.*?;')\n    text = re.sub(regex, ' ', text)\n    text = re.sub('([!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~])', r' \\1 ', text)\n    text = text.replace('\\\\',' \\\\ ')\n    text = re.sub('\\s{2,}', ' ', text)\n    text = re.sub(r'[\\r\\n]+', ' ', text)\n    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n    text = word_tokenize(text)\n    for token in text:\n            try:\n                if any(i.isdigit() for i in token) == False:\n                    if token not in stop_words:\n                        tokens.append(token)\n                else:\n                    tokens.append(token)\n            except Exception as e:\n                print(e, token)\n                pass\n    tokens = \" \".join(tokens)\n    tokens = re.sub(r\"\\s's\\b\", \"'s\", tokens)\n    return tokens\n\ndef preprocess_keywords(keywords):\n    keywords = fix_encoding(keywords)\n    keywords = keywords.split(\",\")\n    keywords = [ele.strip() for ele in keywords if len(keywords)>3]\n    keywords = re.sub(r'[\\r\\n]+', ' ', keywords)\n    keywords = re.sub(r'[^\\x00-\\x7F]+', ' ', keywords)\n    keywords = re.sub(r\"\\s's\\b\", \"'s\", keywords)\n    return keywords\n\ndata_train = pd.read_csv(\"/kaggle/input/originnal-dataset/data_splited_train.csv\", encoding = \"ISO-8859-1\")\ndata_test = pd.read_csv(\"/kaggle/input/originnal-dataset/data_origin_test.csv\", encoding = \"ISO-8859-1\")\ndata_valid = pd.read_csv(\"/kaggle/input/originnal-dataset/data_splited_validate.csv\", encoding = \"ISO-8859-1\")\ndata_train.dropna(subset=['title', 'abstract'], inplace=True)\ndata_train = data_train[data_train['abstract'].str.isnumeric()==False]\ndata_train = data_train[data_train['title'].str.isnumeric()==False]\ndata_train = data_train[data_train['keywords'].str.isnumeric()==False]\ndata_train.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T10:08:05.427755Z","iopub.execute_input":"2023-01-10T10:08:05.428164Z","iopub.status.idle":"2023-01-10T10:08:05.440819Z","shell.execute_reply.started":"2023-01-10T10:08:05.428132Z","shell.execute_reply":"2023-01-10T10:08:05.439315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas()\ndata_train['title'] = data_train['title'].progress_apply(preprocess_text)\ndata_train['abstract'] = data_train['abstract'].progress_apply(preprocess_text)\ndata_train['keywords'] = data_train['keywords'].progress_apply(preprocess_keywords)\ndata_train['title'] = data_train['title'].progress_apply(fix_encoding)\ndata_train['abstract'] = data_train['abstract'].progress_apply(fix_encoding)\n\ndata_valid['title'] = data_valid['title'].progress_apply(preprocess_text)\ndata_valid['abstract'] = data_valid['abstract'].progress_apply(preprocess_text)\ndata_valid['keywords'] = data_valid['keywords'].progress_apply(preprocess_keywords)\ndata_valid['title'] = data_valid['title'].progress_apply(fix_encoding)\ndata_valid['abstract'] = data_valid['abstract'].progress_apply(fix_encoding)\n\ndata_test['title'] = data_test['title'].progress_apply(preprocess_text)\ndata_test['abstract'] = data_test['abstract'].progress_apply(preprocess_text)\ndata_test['keywords'] = data_test['keywords'].progress_apply(preprocess_keywords)\ndata_test['title'] = data_test['title'].progress_apply(fix_encoding)\ndata_test['abstract'] = data_test['abstract'].progress_apply(fix_encoding)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-01-10T10:08:16.469602Z","iopub.execute_input":"2023-01-10T10:08:16.470049Z","iopub.status.idle":"2023-01-10T10:08:22.475569Z","shell.execute_reply.started":"2023-01-10T10:08:16.470013Z","shell.execute_reply":"2023-01-10T10:08:22.473800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train.to_csv(work_path+\"news_preprocessed_train.csv\", index=False)\ndata_valid.to_csv(work_path+\"news_preprocessed_valid.csv\", index=False)\ndata_test.to_csv(work_path+\"news_preprocessed_test.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T10:07:53.332230Z","iopub.status.idle":"2023-01-10T10:07:53.333571Z","shell.execute_reply.started":"2023-01-10T10:07:53.333234Z","shell.execute_reply":"2023-01-10T10:07:53.333265Z"},"trusted":true},"execution_count":null,"outputs":[]}]}